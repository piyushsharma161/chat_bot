{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "dir_path = 'chatterbotenglish'\n",
    "files_list = os.listdir(dir_path + os.sep)\n",
    "\n",
    "questions = list()\n",
    "answers = list()\n",
    "for filepath in files_list:\n",
    "    stream = open( dir_path + os.sep + filepath , 'rb')\n",
    "    docs = yaml.safe_load(stream)\n",
    "    conversations = docs['conversations']\n",
    "    for con in conversations:\n",
    "        if len( con ) > 2 :\n",
    "            questions.append(con[0])\n",
    "            replies = con[ 1 : ]\n",
    "            ans = ''\n",
    "            for rep in replies:\n",
    "                ans += ' ' + rep\n",
    "            answers.append( ans )\n",
    "        elif len( con )> 1:\n",
    "            if type(con[0]) is dict:\n",
    "                for k, v in con[0].items():\n",
    "                    questions.append(k)\n",
    "            else:                             \n",
    "                questions.append(con[0])\n",
    "            if type(con[1]) is dict:\n",
    "                for k, v in con[1].items():\n",
    "                    answers.append(k)\n",
    "            else:                             \n",
    "                answers.append(con[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from tensorflow.keras import layers , activations , models , preprocessing\n",
    "\n",
    "print( tf.VERSION )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_lines = list()\n",
    "for line in answers:\n",
    "    answers_lines.append( '<START> ' + line + ' <END>' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts((questions + answers_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "questions_seq = tokenizer.texts_to_sequences(questions)\n",
    "max_input_length = max([len(seq) for seq in questions_seq])\n",
    "encoder_input_data = pad_sequences( questions_seq , maxlen=max_input_length , padding='post' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_seq = tokenizer.texts_to_sequences(answers_lines)\n",
    "max_output_length = max([len(seq) for seq in answers_seq])\n",
    "decoder_input_data = pad_sequences(answers_seq , maxlen=max_output_length , padding='post' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_target_data = list()\n",
    "for token_seq in answers_seq:\n",
    "    decoder_target_data.append( token_seq[ 1 : ] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "num_tokens = len(tokenizer.word_index) + 1\n",
    "padded_target_lines = pad_sequences( decoder_target_data , maxlen=max_output_length, padding='post' )\n",
    "decoder_target_data  = to_categorical( padded_target_lines , num_tokens )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = tokenizer.word_index\n",
    "max_question_len = encoder_input_data.shape[1]\n",
    "max_answer_len = decoder_input_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(566, 22)\n",
      "(566, 74)\n",
      "(566, 74, 1897)\n"
     ]
    }
   ],
   "source": [
    "print( encoder_input_data.shape )\n",
    "print( decoder_input_data.shape )\n",
    "print( decoder_target_data.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# load the whole embedding into memory\n",
    "import numpy as np\n",
    "embeddings_index = dict()\n",
    "f = open('/projects/glove.6B/glove.6B.200d.txt', encoding = \"utf-8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1 \n",
    "EMBEDDING_DIM =200\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "np.save('encoder_input_data', encoder_input_data) \n",
    "np.save('decoder_input_data', decoder_input_data) \n",
    "np.save('decoder_target_data', decoder_target_data) \n",
    "np.save('embedding_matrix', embedding_matrix) \n",
    "pickle.dump(tokenizer, open(\"tokenizer\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\OF65\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 200)    379400      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 200)    379400      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 200), (None, 320800      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 200),  320800      embedding_1[0][0]                \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 1897)   381297      lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,781,697\n",
      "Trainable params: 1,781,697\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "encoder_inputs = tf.keras.layers.Input(shape=( None , ))\n",
    "encoder_embedding = tf.keras.layers.Embedding( num_tokens, 200 , mask_zero=True , weights=[embedding_matrix] ) (encoder_inputs)\n",
    "encoder_outputs , state_h , state_c = tf.keras.layers.LSTM( 200 , return_state=True )( encoder_embedding )\n",
    "encoder_states = [ state_h , state_c ]\n",
    "\n",
    "decoder_inputs = tf.keras.layers.Input(shape=( None ,  ))\n",
    "decoder_embedding = tf.keras.layers.Embedding( num_tokens, 200 , mask_zero=True, weights=[embedding_matrix]) (decoder_inputs)\n",
    "decoder_lstm = tf.keras.layers.LSTM( 200 , return_state=True , return_sequences=True )\n",
    "decoder_outputs , _ , _ = decoder_lstm ( decoder_embedding , initial_state=encoder_states )\n",
    "decoder_dense = tf.keras.layers.Dense( num_tokens , activation=tf.keras.activations.softmax ) \n",
    "output = decoder_dense ( decoder_outputs )\n",
    "\n",
    "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], output )\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# simple early stopping\n",
    "#es = EarlyStopping(monitor='loss', mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\OF65\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\OF65\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/100\n",
      "566/566 [==============================] - 13s 23ms/sample - loss: 6.3983 - acc: 0.1004\n",
      "Epoch 2/100\n",
      "566/566 [==============================] - 10s 18ms/sample - loss: 5.6166 - acc: 0.1392\n",
      "Epoch 3/100\n",
      "566/566 [==============================] - 11s 19ms/sample - loss: 5.4740 - acc: 0.1514\n",
      "Epoch 4/100\n",
      "566/566 [==============================] - 10s 19ms/sample - loss: 5.3713 - acc: 0.1626\n",
      "Epoch 5/100\n",
      "566/566 [==============================] - 11s 20ms/sample - loss: 5.2345 - acc: 0.1712\n",
      "Epoch 6/100\n",
      "566/566 [==============================] - 12s 21ms/sample - loss: 5.1566 - acc: 0.1764\n",
      "Epoch 7/100\n",
      "566/566 [==============================] - 12s 21ms/sample - loss: 5.0551 - acc: 0.1852\n",
      "Epoch 8/100\n",
      "566/566 [==============================] - 11s 20ms/sample - loss: 4.9530 - acc: 0.1965\n",
      "Epoch 9/100\n",
      "566/566 [==============================] - 10s 18ms/sample - loss: 4.8230 - acc: 0.2094\n",
      "Epoch 10/100\n",
      "566/566 [==============================] - 10s 19ms/sample - loss: 4.7432 - acc: 0.2211\n",
      "Epoch 11/100\n",
      "566/566 [==============================] - 10s 18ms/sample - loss: 4.6390 - acc: 0.2371\n",
      "Epoch 12/100\n",
      "566/566 [==============================] - 10s 18ms/sample - loss: 4.5438 - acc: 0.2459\n",
      "Epoch 13/100\n",
      "566/566 [==============================] - 11s 20ms/sample - loss: 4.4309 - acc: 0.2520\n",
      "Epoch 14/100\n",
      "566/566 [==============================] - 11s 19ms/sample - loss: 4.3414 - acc: 0.2587\n",
      "Epoch 15/100\n",
      "566/566 [==============================] - 11s 19ms/sample - loss: 4.2405 - acc: 0.2621\n",
      "Epoch 16/100\n",
      "566/566 [==============================] - 11s 19ms/sample - loss: 4.1568 - acc: 0.2675\n",
      "Epoch 17/100\n",
      "566/566 [==============================] - 10s 18ms/sample - loss: 4.0501 - acc: 0.2755\n",
      "Epoch 18/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 3.9467 - acc: 0.2821\n",
      "Epoch 19/100\n",
      "566/566 [==============================] - 9s 17ms/sample - loss: 3.8504 - acc: 0.2870\n",
      "Epoch 20/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 3.7706 - acc: 0.2987\n",
      "Epoch 21/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 3.6740 - acc: 0.3039\n",
      "Epoch 22/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 3.5862 - acc: 0.3124\n",
      "Epoch 23/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 3.4981 - acc: 0.3188\n",
      "Epoch 24/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 3.4150 - acc: 0.3254\n",
      "Epoch 25/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 3.3176 - acc: 0.3337\n",
      "Epoch 26/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 3.2228 - acc: 0.3463\n",
      "Epoch 27/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 3.1402 - acc: 0.3560\n",
      "Epoch 28/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 3.0573 - acc: 0.3669\n",
      "Epoch 29/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 2.9674 - acc: 0.3759\n",
      "Epoch 30/100\n",
      "566/566 [==============================] - 9s 17ms/sample - loss: 2.8866 - acc: 0.3891\n",
      "Epoch 31/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 2.8010 - acc: 0.4018\n",
      "Epoch 32/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 2.7147 - acc: 0.4116\n",
      "Epoch 33/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 2.6331 - acc: 0.4286\n",
      "Epoch 34/100\n",
      "566/566 [==============================] - 9s 17ms/sample - loss: 2.5504 - acc: 0.4432\n",
      "Epoch 35/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 2.4719 - acc: 0.4564\n",
      "Epoch 36/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 2.4042 - acc: 0.4731\n",
      "Epoch 37/100\n",
      "566/566 [==============================] - 10s 18ms/sample - loss: 2.3110 - acc: 0.4946\n",
      "Epoch 38/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 2.2314 - acc: 0.5092\n",
      "Epoch 39/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 2.1670 - acc: 0.5260\n",
      "Epoch 40/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 2.0960 - acc: 0.5446\n",
      "Epoch 41/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 2.0185 - acc: 0.5614\n",
      "Epoch 42/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 1.9578 - acc: 0.5817\n",
      "Epoch 43/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 1.8809 - acc: 0.5937\n",
      "Epoch 44/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 1.8035 - acc: 0.6103\n",
      "Epoch 45/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 1.7538 - acc: 0.6278\n",
      "Epoch 46/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 1.6859 - acc: 0.6466\n",
      "Epoch 47/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 1.6243 - acc: 0.6604\n",
      "Epoch 48/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 1.5704 - acc: 0.6771\n",
      "Epoch 49/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 1.5177 - acc: 0.6906\n",
      "Epoch 50/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 1.4508 - acc: 0.7047\n",
      "Epoch 51/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 1.3944 - acc: 0.7181\n",
      "Epoch 52/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 1.3493 - acc: 0.7289\n",
      "Epoch 53/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 1.2926 - acc: 0.7427\n",
      "Epoch 54/100\n",
      "566/566 [==============================] - 9s 17ms/sample - loss: 1.2508 - acc: 0.7543\n",
      "Epoch 55/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 1.1920 - acc: 0.7630\n",
      "Epoch 56/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 1.1503 - acc: 0.7785\n",
      "Epoch 57/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 1.1099 - acc: 0.7858\n",
      "Epoch 58/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 1.0547 - acc: 0.8031\n",
      "Epoch 59/100\n",
      "566/566 [==============================] - 9s 17ms/sample - loss: 1.0036 - acc: 0.8094\n",
      "Epoch 60/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 0.9760 - acc: 0.8180\n",
      "Epoch 61/100\n",
      "566/566 [==============================] - 10s 18ms/sample - loss: 0.9317 - acc: 0.8271\n",
      "Epoch 62/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 0.9001 - acc: 0.8351\n",
      "Epoch 63/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 0.8604 - acc: 0.8484\n",
      "Epoch 64/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 0.8145 - acc: 0.8533\n",
      "Epoch 65/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 0.7944 - acc: 0.8583\n",
      "Epoch 66/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 0.7612 - acc: 0.8628\n",
      "Epoch 67/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 0.7223 - acc: 0.8775\n",
      "Epoch 68/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 0.6913 - acc: 0.8825\n",
      "Epoch 69/100\n",
      "566/566 [==============================] - 10s 18ms/sample - loss: 0.6575 - acc: 0.8868\n",
      "Epoch 70/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 0.6355 - acc: 0.8905\n",
      "Epoch 71/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 0.5993 - acc: 0.9004\n",
      "Epoch 72/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 0.5764 - acc: 0.9044\n",
      "Epoch 73/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 0.5613 - acc: 0.9054\n",
      "Epoch 74/100\n",
      "566/566 [==============================] - 9s 17ms/sample - loss: 0.5264 - acc: 0.9152\n",
      "Epoch 75/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 0.5113 - acc: 0.9169\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "566/566 [==============================] - 10s 17ms/sample - loss: 0.4856 - acc: 0.9250\n",
      "Epoch 77/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 0.4643 - acc: 0.9268\n",
      "Epoch 78/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 0.4400 - acc: 0.9300\n",
      "Epoch 79/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 0.4296 - acc: 0.9314\n",
      "Epoch 80/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 0.4041 - acc: 0.9360\n",
      "Epoch 81/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 0.3883 - acc: 0.9401\n",
      "Epoch 82/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 0.3689 - acc: 0.9423\n",
      "Epoch 83/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 0.3622 - acc: 0.9433\n",
      "Epoch 84/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 0.3350 - acc: 0.9471\n",
      "Epoch 85/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 0.3237 - acc: 0.9499\n",
      "Epoch 86/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 0.3118 - acc: 0.9499\n",
      "Epoch 87/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 0.3008 - acc: 0.9536\n",
      "Epoch 88/100\n",
      "566/566 [==============================] - 10s 18ms/sample - loss: 0.2853 - acc: 0.9559\n",
      "Epoch 89/100\n",
      "566/566 [==============================] - 12s 21ms/sample - loss: 0.2730 - acc: 0.9563\n",
      "Epoch 90/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 0.2647 - acc: 0.9588\n",
      "Epoch 91/100\n",
      "566/566 [==============================] - 10s 18ms/sample - loss: 0.2505 - acc: 0.9609\n",
      "Epoch 92/100\n",
      "566/566 [==============================] - 10s 18ms/sample - loss: 0.2421 - acc: 0.9599\n",
      "Epoch 93/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 0.2315 - acc: 0.9629\n",
      "Epoch 94/100\n",
      "566/566 [==============================] - 10s 18ms/sample - loss: 0.2219 - acc: 0.9616\n",
      "Epoch 95/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 0.2092 - acc: 0.9646\n",
      "Epoch 96/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 0.2064 - acc: 0.9633\n",
      "Epoch 97/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 0.1997 - acc: 0.9661\n",
      "Epoch 98/100\n",
      "566/566 [==============================] - 10s 17ms/sample - loss: 0.1875 - acc: 0.9676\n",
      "Epoch 99/100\n",
      "566/566 [==============================] - 10s 18ms/sample - loss: 0.1816 - acc: 0.9694\n",
      "Epoch 100/100\n",
      "566/566 [==============================] - 10s 18ms/sample - loss: 0.1764 - acc: 0.9674\n"
     ]
    }
   ],
   "source": [
    "#history = model.fit([encoder_input_data , decoder_input_data], decoder_target_data, batch_size=50, epochs=100, callbacks=[es]).history \n",
    "history = model.fit([encoder_input_data , decoder_input_data], decoder_target_data, batch_size=50, epochs=100).history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save( 'model_chatbots1.h5' )\n",
    "pickle.dump(history, open(\"history_chatbots1.p\", \"wb\"))\n",
    "\n",
    "# load it back\n",
    "#model = load_model('model_chatbots1.h5')\n",
    "#history = pickle.load(open(\"history_chatbots1.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_inference_models():\n",
    "    \n",
    "    encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)\n",
    "    \n",
    "    decoder_state_input_h = tf.keras.layers.Input(shape=( 200 ,))\n",
    "    decoder_state_input_c = tf.keras.layers.Input(shape=( 200 ,))\n",
    "    \n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    \n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "        decoder_embedding , initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = tf.keras.models.Model(\n",
    "        [decoder_inputs] + decoder_states_inputs,\n",
    "        [decoder_outputs] + decoder_states)\n",
    "    \n",
    "    return encoder_model , decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_tokens( sentence : str ):\n",
    "    words = sentence.lower().split()\n",
    "    tokens_list = list()\n",
    "    for word in words:\n",
    "        tokens_list.append( word_dict[ word ] ) \n",
    "    return preprocessing.sequence.pad_sequences( [tokens_list] , maxlen=max_question_len , padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_model , dec_model = make_inference_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_model.save( 'enc_model.h5' )\n",
    "dec_model.save( 'dec_model.h5' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter question : hi\n",
      "hello\n",
      "Enter question : hi\n",
      "hello\n",
      "Enter question : hi\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "for _ in range(3):\n",
    "    try:\n",
    "        states_values = enc_model.predict( str_to_tokens( input( 'Enter question : ' ) ) )\n",
    "        empty_target_seq = np.zeros( ( 1 , 1 ) )\n",
    "        empty_target_seq[0, 0] = word_dict['start']\n",
    "        stop_condition = False\n",
    "        decoded_translation = ''\n",
    "        while not stop_condition :\n",
    "            dec_outputs , h , c = dec_model.predict([ empty_target_seq ] + states_values )\n",
    "            sampled_word_index = np.argmax( dec_outputs[0, -1, :] )\n",
    "            sampled_word = None\n",
    "            for word , index in word_dict.items() :\n",
    "                if sampled_word_index == index :\n",
    "                    decoded_translation += ' {}'.format( word )\n",
    "                    sampled_word = word\n",
    "        \n",
    "            if sampled_word == 'end' or len(decoded_translation.split()) > max_answer_len:\n",
    "                stop_condition = True\n",
    "            \n",
    "            empty_target_seq = np.zeros( ( 1 , 1 ) )  \n",
    "            empty_target_seq[ 0 , 0 ] = sampled_word_index\n",
    "            states_values = [ h , c ] \n",
    "\n",
    "        ans = [w for w in decoded_translation.split() if not w in ['end']]\n",
    "        ans = ' '.join(ans)\n",
    "        print(ans)\n",
    "    except Exception as e:\n",
    "        print(\"sorry, can't answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ef59a1c748>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(history['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
